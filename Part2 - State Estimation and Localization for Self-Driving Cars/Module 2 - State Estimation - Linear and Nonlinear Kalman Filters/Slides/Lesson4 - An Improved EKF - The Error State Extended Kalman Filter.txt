In the last video, we introduced the Extended
Kalman Filter, which uses
local linearization as a way to allow us to apply the Kalman
filter equations to non-linear systems. In this video, we're going to look
at a variant of the EKF called the Error-State Extended
Kalman Filter, or ES-EKF, which
has a couple of nice properties that will come in handy later
in the course. By the end of this video, you'll be able to describe the error state
formulation of the Extended
Kalman Filter, and describe the
advantages of the error state EKF
over the vanilla EKF that you learned about in the
previous video. The idea behind
the error state EKF is really very simple. We're going to
start thinking about our vehicle state, x, as being composed
of two parts; a large part called the nominal state, x hat, and a small part called the error state, Delta x. We can think of
a simple example of tracking the position
of a car over time. The green line shows the true position
of the car, which is the quantity we're trying to estimate. The red line is
the nominal state, or our best guess what the true state could
be based on what we know about the
car's motion model and acceleration and
breaking inputs. Of course,
our motion model is never perfect, and there is always some random process noise. These errors build up over time as we integrate
the motion model. We can think of
the error state as the place where all of these modelling errors and process noise
accumulate over time, so that the error state is just the
difference between the nominal state and the true state at
any given time. If we can figure out what the error state is, we can actually use
it as a correction to the nominal state to bring us closer to
the true state. So, in the error
state EKF, instead of doing
Kalman filtering on the full state
which might have lots of complicated
non-linear behaviors, we're going to
use the EKF to estimate the error
state instead, and then use
the estimate of the error state as a correction to
the nominal state. What this means
mathematically is that we're going to rearrange our
linearized motion model so that we now have an equation
that can tell us how the difference between the true state at time, k, and our predicted
state at time, k, is related to
the same difference at time, k minus one. These differences
are exactly the error states we
just talked about; Delta x sub k and
Delta x sub k minus one, and the equations
relating them are called the error
state kinematics. We can also re-express our linearized
measurement model in terms of the error
state directly. We can use this error
state formulation of the EKF in
a very similar way to the vanilla EKF. We start off by updating the nominal state using the non-linear
motion model and our current best
estimate of the state. We could do this a bunch of times before ever getting a measurement for the correction step. So, the current
best estimate might be x check or x hat. We also need to keep track of the state covariance, which grows as
we integrate more and more
process noise from the motion model. Note that again, the previous
covariance estimate could be P check or P hat depending
on whether we used a measurement to
do a correction step. We can repeat the loop updating the
nominal state and the error state covariance for as long as we like until we receive
the measurement and want to do
a correction. When this happens,
we can compute the Kalman gain as usual, and then compute
the best estimate of the error state using
the Kalman gain, the measurement, and our nonlinear
measurement model. Now, here's where things
are little different. Once we have
an estimate for the mean of
the error state, we want to use
this to update the nominal state and
correct the error. We can do that by just adding our estimate
of the error state to the nominal state to get the correct state estimate for the full state. Finally, we can update the state covariance using the usual equations.
That's it. This process
goes on forever, or at least until the vehicle runs
out of gas. So, why would we
actually want to use the error state EKF
in practice? Well, there are two
good reasons to use it. One reason is that
it can often work better than the
vanilla EKF because the small error
state is more amenable to
linear filtering than the large
nominal state, which we can integrate
non-linearly. The other reason is that the error state
formulation makes it much easier to work with
constrained quantities like rotations, which
will come in handy a bit later in the course. The reason for
this is that we don't necessarily
have to use plane vector addition to break down the state. In fact, we could use any generalized
composition operation we like as long as it gives us a consistent way
of incorporating small perturbations
into the nominal state. If this all sounds
a bit abstract right now, don't worry. Later in the
course, we'll use the error state
EKF to help us deal with rotations
in 3D space, which are
a very common type of constraint quantity. Let's recap. The error
state formulation of the EKF separates the vehicle state into a large nominal state and a small error state. The nominal state
keeps track of what the motion model predicts the states should be, while the error state captures the
modelling errors and process noise that
accumulate over time. In the error state EKF, we estimate
this small error state and use it as a correction to
the nominal state. This is the main
difference between the error state EKF
and the vanilla EKF, which estimates
the full state. Keep in mind that
both formulations still rely on
local linearization. The error state
EKF has a couple of advantages over
the vanilla EKF. The first is that
it simply performs better because
the evolution of the error state tends to be closer to linear. The other is that the error state
formulation makes it easier to handle special quantities
like 3D rotations as we'll see later
in the course. In the next video, we'll discuss some of the shortcomings
of the EKF, and how local
linearization can break down creating a potentially
dangerous situation for a self-driving car.